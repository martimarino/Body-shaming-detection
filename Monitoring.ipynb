{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb75898",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afefbb",
   "metadata": {
    "id": "86afefbb"
   },
   "source": [
    "# Online monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17116931",
   "metadata": {
    "id": "17116931"
   },
   "source": [
    "## - Extract peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6461cf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4416,
     "status": "ok",
     "timestamp": 1657795609250,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "d6461cf5",
    "outputId": "8ecc070d-a96a-4985-c11f-6be34397d63b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# 2022-03-10\n",
    "# 2022-04-09\n",
    "# 2022-06-18\n",
    "# 2022-07-20\n",
    "\n",
    "def extract_peaks():\n",
    "    \n",
    "    peaks = {'2022-03': '2022-03-10', \n",
    "             '2022-04': '2022-04-09',\n",
    "             '2022-06': '2022-06-18', \n",
    "             '2022-07': '2022-07-20'}\n",
    "\n",
    "    i = 0\n",
    "    for key, value in peaks.items():\n",
    "        \n",
    "        # may is period3\n",
    "        if i == 2:\n",
    "            i+=1\n",
    "        i+=1\n",
    "    \n",
    "        df = pd.read_csv('cleaned/'+key+'-cleaned.csv', index_col=False, delimiter=\",\")\n",
    "\n",
    "        end_peak = value+' 23:59:59+00:00'\n",
    "        start_peak = value+' 00:00:00+00:00'\n",
    "        start = time.strptime(start_peak, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        end = time.strptime(end_peak, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        peak = df[(df['datetime'] > start_peak) & (df['datetime'] < end_peak)]\n",
    "\n",
    "        peak.to_csv('./monitoring/period'+str(i)+'.csv', index=False, sep=',')\n",
    "    \n",
    "    print(\"Peaks extracted \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79f72a",
   "metadata": {},
   "source": [
    "## - Extract labelled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0b6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_labeled(in_file, out_file):\n",
    "\n",
    "    df = pd.read_csv(in_file, index_col=False, delimiter=\",\")\n",
    "\n",
    "    tweets_list = []\n",
    "    print(df.shape)\n",
    "\n",
    "    labeled = df[(df.target == '0') | (df.target == '1')]\n",
    "    labeled.to_csv(out_file, index=False, sep=',')\n",
    "\n",
    "    return (labeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68b40d",
   "metadata": {
    "id": "5e68b40d"
   },
   "source": [
    "# Concept drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d860c7",
   "metadata": {},
   "source": [
    "## - Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "311e7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "\n",
    "def cd_training(path, data, i, c):\n",
    "\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    tweets = data.text\n",
    "    targets = data.target\n",
    "    perc = 75\n",
    "    model = {'name': 'ComplementNB', 'fun': ComplementNB()}\n",
    "\n",
    "    # model building\n",
    "    model['pipeline'] = Pipeline(steps=[('vect', CountVectorizer(ngram_range=(1, 1))),\n",
    "                                ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n",
    "                                ('fselect', SelectPercentile(chi2, percentile=perc)),\n",
    "                                #('fselect', SelectKBest(chi2, k='all')),      \n",
    "                                ('clf', model['fun'])])\n",
    "\n",
    "    m = model['pipeline'].fit(tweets, targets)\n",
    "    \n",
    "    print(\"Number of features: \", len(model['pipeline']['vect'].vocabulary_))\n",
    "    \n",
    "    # save model\n",
    "    if c =='i':\n",
    "        filename = model['name']+'_interval'+str(i)+'.sav'\n",
    "    elif c == 's':\n",
    "        filename = model['name']+'_slide'+str(i)+'.sav'\n",
    "    \n",
    "    pickle.dump(m, open(path+'/'+filename, 'wb'))\n",
    "\n",
    "    print(\"\\nModel correctly saved!\\n\")\n",
    "    print('─' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf335ec",
   "metadata": {},
   "source": [
    "## - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e2e3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cd_test(path, data, i, c):\n",
    "    \n",
    "    print(\"Testing...\")\n",
    "\n",
    "    tweets = data['text']\n",
    "    targets = data['target']\n",
    "\n",
    "    \n",
    "    if c == 'st':\n",
    "        loaded_model = pickle.load(open('models_result/75/models_75/'+model['name']+'.sav', 'rb'))\n",
    "    elif c == 'i':\n",
    "        loaded_model = pickle.load(open(path+model['name']+'_interval'+str(i)+'.sav', 'rb'))\n",
    "    elif c == 's':\n",
    "        loaded_model = pickle.load(open(path+model['name']+'_slide'+str(i)+'.sav', 'rb'))\n",
    "    \n",
    "    print(\"Number of features: \", len(loaded_model['vect'].vocabulary_))\n",
    "\n",
    "    score = loaded_model.score(tweets, targets)\n",
    "    print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "    y_predict = loaded_model.predict(tweets)\n",
    "\n",
    "    rep = classification_report(targets, y_predict,\n",
    "                                          target_names=['0', '1'])\n",
    "    print(rep, '\\n')\n",
    "\n",
    "    # save reports\n",
    "    rep = classification_report(targets, y_predict,\n",
    "                                target_names=['0', '1'], output_dict=True)\n",
    "    df = pd.DataFrame(rep).transpose()\n",
    "    \n",
    "    if c == 'st':\n",
    "        df.to_csv(path+'period'+str(i)+'-report-ComplementNB.csv')\n",
    "    if c == 'i':\n",
    "        df.to_csv(path+'interval'+str(i)+'-report-ComplementNB.csv')\n",
    "    elif c == 's':\n",
    "        df.to_csv(path+'slide'+str(i)+'-report-ComplementNB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31479da",
   "metadata": {},
   "source": [
    "## - Create window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "119c5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(path, i, file1, file2, c):\n",
    "\n",
    "    print(\"Creating window...\")\n",
    "    df1 = pd.read_csv(file1, index_col=False, delimiter=\",\")\n",
    "    df1.sort_values('datetime', inplace=True, ascending=True)\n",
    "    print(\"Previous window: \", df1.shape)\n",
    "    \n",
    "    if c == 's':\n",
    "        if i == 1:\n",
    "            data1 = df1.tail(-176)\n",
    "        elif i == 6:\n",
    "            data1 = df1.tail(-60)\n",
    "        else:\n",
    "            data1 = df1.tail(-80)\n",
    "        print(\"Tweets deleted: \", data1.shape)\n",
    "        \n",
    "    data2 = pd.read_csv(file2, index_col=False, delimiter=\",\")\n",
    "    data2.sort_values('datetime', inplace=True, ascending=True)\n",
    "    print(\"New tweets: \", data2.shape)\n",
    "    \n",
    "    if c == 'i':\n",
    "        window = pd.concat([df1,data2])\n",
    "    elif c == 's':\n",
    "        window = pd.concat([data1,data2])\n",
    "        \n",
    "    print(\"New window: \", window.shape)\n",
    "    \n",
    "    if c == 'i':\n",
    "        window_name = path+'interval'+str(i)+'.csv'\n",
    "    elif c == 's':\n",
    "        window_name = path+'slide'+str(i)+'.csv'\n",
    "    window.to_csv(window_name, index=False)\n",
    "    \n",
    "    return window_name, window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85d8e1",
   "metadata": {},
   "source": [
    "\n",
    "## - Get files for building a new window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5009e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path, i, c):\n",
    "    \n",
    "    list = []\n",
    "    j = i-1\n",
    "    if i == 1:\n",
    "        list.append('monitoring/2021-12-01-labeled-only.csv')\n",
    "        list.append('monitoring/2022-02-labeled-only.csv')\n",
    "        \n",
    "    else: # 2 3 4 5 6\n",
    "        if c == 'i':\n",
    "            list.append(path+'interval'+str(j)+'.csv')\n",
    "        elif c == 's':\n",
    "            list.append(path+'slide'+str(j)+'.csv')\n",
    "        list.append('labeled/period'+str(j)+'-labeled-only.csv')\n",
    "    \n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86920439",
   "metadata": {
    "id": "86920439"
   },
   "source": [
    "## - Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e2fe2eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6415,
     "status": "ok",
     "timestamp": 1657795812698,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "6e2fe2eb",
    "outputId": "bc4a176d-fd99-46c0-e82c-9557710bd712",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "def static_cd(model):\n",
    "    \n",
    "    static_path = 'monitoring/concept_drift/static/'\n",
    "        \n",
    "    for i in range(1,6):\n",
    "        \n",
    "        print(\"\\n*********** STATIC MODEL ************\\n\")\n",
    "        \n",
    "        test_set_file = './labeled/period'+str(i)+'-labeled-only.csv'\n",
    "        test_data = pd.read_csv(test_set_file, index_col=False, delimiter=\",\")\n",
    "\n",
    "        test_data = preprocess(test_data)\n",
    "        test_data = elaborate(test_data)\n",
    "\n",
    "        cd_test(static_path, test_data, i, 'st')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df5686",
   "metadata": {
    "id": "f8df5686"
   },
   "source": [
    "## - Sliding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "518db23f",
   "metadata": {
    "id": "518db23f"
   },
   "outputs": [],
   "source": [
    "def sliding_cd(model):       \n",
    "    \n",
    "    sliding_path = 'monitoring/concept_drift/sliding/'\n",
    "\n",
    "    for i in range(1,7):\n",
    "        \n",
    "        print(\"\\n*********** SLIDING MODEL ************\\n\")\n",
    "        \n",
    "        #create window\n",
    "        list = get_files(sliding_path , i, 's')  # old and new tweets\n",
    "        print(\"Files to merge: \", list)\n",
    "        file1 = list[0]\n",
    "        file2 = list[1]\n",
    "        \n",
    "        slide_name, slide = create_window(sliding_path, i, file1, file2, 's')\n",
    "        print(\"File created: \", slide_name, \"\\n\")\n",
    "\n",
    "        #train\n",
    "        training_data = preprocess(slide)\n",
    "        training_data = elaborate(training_data)\n",
    "        \n",
    "        cd_training(sliding_path, training_data, i, 's')\n",
    "        \n",
    "        #test on next month\n",
    "        \n",
    "        if i < 6:\n",
    "        \n",
    "            test_set_file = './labeled/period'+str(i)+'-labeled-only.csv'\n",
    "            test_data = pd.read_csv(test_set_file, index_col=False, delimiter=\",\")\n",
    "\n",
    "            test_data = preprocess(test_data)\n",
    "            test_data = elaborate(test_data)\n",
    "\n",
    "            cd_test(sliding_path, test_data, i, 's') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7d5c5",
   "metadata": {
    "id": "17e7d5c5"
   },
   "source": [
    "## - Incremental model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4febfb93",
   "metadata": {
    "id": "4febfb93",
    "outputId": "b20c545f-01f0-4af6-c217-08e90b992d9e"
   },
   "outputs": [],
   "source": [
    "def incremental_cd(model):\n",
    "    \n",
    "    incremental_path = 'monitoring/concept_drift/incremental/'\n",
    "\n",
    "    for i in range(1,7):\n",
    "        \n",
    "        print(\"\\n*********** INCREMENTAL MODEL ************\\n\")\n",
    "        \n",
    "        #create window\n",
    "        list = get_files(incremental_path, i, 'i')  # old and new tweets\n",
    "        print(\"Files to merge: \", list)\n",
    "        file1 = list[0]\n",
    "        file2 = list[1]\n",
    "        \n",
    "        interval_name, interval = create_window(incremental_path, i, file1, file2, 'i')\n",
    "        print(\"File created: \", interval_name, \"\\n\")\n",
    "        \n",
    "        #train\n",
    "        training_data = preprocess(interval)\n",
    "        training_data = elaborate(training_data)\n",
    "        \n",
    "        cd_training(incremental_path, training_data, i, 'i') \n",
    "        \n",
    "        #test on next month\n",
    "        \n",
    "        if i < 6:\n",
    "                    \n",
    "            test_set_file = './labeled/period'+str(i)+'-labeled-only.csv'\n",
    "            test_data = pd.read_csv(test_set_file, index_col=False, delimiter=\",\")\n",
    "\n",
    "            test_data = preprocess(test_data)\n",
    "            test_data = elaborate(test_data)\n",
    "\n",
    "            cd_test(incremental_path, test_data, i, 'i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcff96",
   "metadata": {},
   "source": [
    "## - Concept drift main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0affc392",
   "metadata": {
    "id": "0affc392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********** STATIC MODEL ************\n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4669\n",
      "Test score: 73.75 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73        40\n",
      "           1       0.73      0.75      0.74        40\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.74      0.74      0.74        80\n",
      "weighted avg       0.74      0.74      0.74        80\n",
      " \n",
      "\n",
      "\n",
      "*********** STATIC MODEL ************\n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4669\n",
      "Test score: 72.50 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74        40\n",
      "           1       0.75      0.68      0.71        40\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.73      0.73      0.72        80\n",
      "weighted avg       0.73      0.72      0.72        80\n",
      " \n",
      "\n",
      "\n",
      "*********** STATIC MODEL ************\n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4669\n",
      "Test score: 73.75 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75        40\n",
      "           1       0.76      0.70      0.73        40\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.74      0.74      0.74        80\n",
      "weighted avg       0.74      0.74      0.74        80\n",
      " \n",
      "\n",
      "\n",
      "*********** STATIC MODEL ************\n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4669\n",
      "Test score: 66.25 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68        40\n",
      "           1       0.69      0.60      0.64        40\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.67      0.66      0.66        80\n",
      "weighted avg       0.67      0.66      0.66        80\n",
      " \n",
      "\n",
      "\n",
      "*********** STATIC MODEL ************\n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4669\n",
      "Test score: 60.00 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59        30\n",
      "           1       0.59      0.63      0.61        30\n",
      "\n",
      "    accuracy                           0.60        60\n",
      "   macro avg       0.60      0.60      0.60        60\n",
      "weighted avg       0.60      0.60      0.60        60\n",
      " \n",
      "\n",
      "\n",
      "*********** INCREMENTAL MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/2021-12-01-labeled-only.csv', 'monitoring/2022-02-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "New tweets:  (176, 4)\n",
      "New window:  (1752, 4)\n",
      "File created:  monitoring/concept_drift/incremental/interval1.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4734\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4734\n",
      "Test score: 71.25 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73        40\n",
      "           1       0.74      0.65      0.69        40\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.72      0.71      0.71        80\n",
      "weighted avg       0.72      0.71      0.71        80\n",
      " \n",
      "\n",
      "\n",
      "*********** INCREMENTAL MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/incremental/interval1.csv', 'labeled/period1-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1752, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1832, 4)\n",
      "File created:  monitoring/concept_drift/incremental/interval2.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  5101\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  5101\n",
      "Test score: 73.75 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76        40\n",
      "           1       0.81      0.62      0.70        40\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.75      0.74      0.73        80\n",
      "weighted avg       0.75      0.74      0.73        80\n",
      " \n",
      "\n",
      "\n",
      "*********** INCREMENTAL MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/incremental/interval2.csv', 'labeled/period2-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1832, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1912, 4)\n",
      "File created:  monitoring/concept_drift/incremental/interval3.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  5238\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  5238\n",
      "Test score: 72.50 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74        40\n",
      "           1       0.75      0.68      0.71        40\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.73      0.73      0.72        80\n",
      "weighted avg       0.73      0.72      0.72        80\n",
      " \n",
      "\n",
      "\n",
      "*********** INCREMENTAL MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/incremental/interval3.csv', 'labeled/period3-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1912, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1992, 4)\n",
      "File created:  monitoring/concept_drift/incremental/interval4.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  5364\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  5364\n",
      "Test score: 70.00 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71        40\n",
      "           1       0.71      0.68      0.69        40\n",
      "\n",
      "    accuracy                           0.70        80\n",
      "   macro avg       0.70      0.70      0.70        80\n",
      "weighted avg       0.70      0.70      0.70        80\n",
      " \n",
      "\n",
      "\n",
      "*********** INCREMENTAL MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/incremental/interval4.csv', 'labeled/period4-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1992, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (2072, 4)\n",
      "File created:  monitoring/concept_drift/incremental/interval5.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  5536\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  5536\n",
      "Test score: 66.67 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68        30\n",
      "           1       0.68      0.63      0.66        30\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.67      0.67      0.67        60\n",
      "weighted avg       0.67      0.67      0.67        60\n",
      " \n",
      "\n",
      "\n",
      "*********** INCREMENTAL MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/incremental/interval5.csv', 'labeled/period5-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (2072, 4)\n",
      "New tweets:  (60, 4)\n",
      "New window:  (2132, 4)\n",
      "File created:  monitoring/concept_drift/incremental/interval6.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  5637\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "\n",
      "*********** SLIDING MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/2021-12-01-labeled-only.csv', 'monitoring/2022-02-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "Tweets deleted:  (1400, 4)\n",
      "New tweets:  (176, 4)\n",
      "New window:  (1576, 4)\n",
      "File created:  monitoring/concept_drift/sliding/slide1.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4406\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4406\n",
      "Test score: 73.75 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75        40\n",
      "           1       0.76      0.70      0.73        40\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.74      0.74      0.74        80\n",
      "weighted avg       0.74      0.74      0.74        80\n",
      " \n",
      "\n",
      "\n",
      "*********** SLIDING MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/sliding/slide1.csv', 'labeled/period1-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "Tweets deleted:  (1496, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1576, 4)\n",
      "File created:  monitoring/concept_drift/sliding/slide2.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4778\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4778\n",
      "Test score: 76.25 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79        40\n",
      "           1       0.86      0.62      0.72        40\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.78      0.76      0.76        80\n",
      "weighted avg       0.78      0.76      0.76        80\n",
      " \n",
      "\n",
      "\n",
      "*********** SLIDING MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/sliding/slide2.csv', 'labeled/period2-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "Tweets deleted:  (1496, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1576, 4)\n",
      "File created:  monitoring/concept_drift/sliding/slide3.csv \n",
      "\n",
      "Preprocessing done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4759\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4759\n",
      "Test score: 71.25 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74        40\n",
      "           1       0.76      0.62      0.68        40\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.72      0.71      0.71        80\n",
      "weighted avg       0.72      0.71      0.71        80\n",
      " \n",
      "\n",
      "\n",
      "*********** SLIDING MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/sliding/slide3.csv', 'labeled/period3-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "Tweets deleted:  (1496, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1576, 4)\n",
      "File created:  monitoring/concept_drift/sliding/slide4.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4685\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4685\n",
      "Test score: 71.25 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        40\n",
      "           1       0.73      0.68      0.70        40\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.71      0.71      0.71        80\n",
      "weighted avg       0.71      0.71      0.71        80\n",
      " \n",
      "\n",
      "\n",
      "*********** SLIDING MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/sliding/slide4.csv', 'labeled/period4-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "Tweets deleted:  (1496, 4)\n",
      "New tweets:  (80, 4)\n",
      "New window:  (1576, 4)\n",
      "File created:  monitoring/concept_drift/sliding/slide5.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4728\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Testing...\n",
      "Number of features:  4728\n",
      "Test score: 63.33 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62        30\n",
      "           1       0.62      0.67      0.65        30\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.63      0.63      0.63        60\n",
      "weighted avg       0.63      0.63      0.63        60\n",
      " \n",
      "\n",
      "\n",
      "*********** SLIDING MODEL ************\n",
      "\n",
      "Files to merge:  ['monitoring/concept_drift/sliding/slide5.csv', 'labeled/period5-labeled-only.csv']\n",
      "Creating window...\n",
      "Previous window:  (1576, 4)\n",
      "Tweets deleted:  (1516, 4)\n",
      "New tweets:  (60, 4)\n",
      "New window:  (1576, 4)\n",
      "File created:  monitoring/concept_drift/sliding/slide6.csv \n",
      "\n",
      "Preprocessing done\n",
      "Elaboration done\n",
      "\n",
      "\n",
      "Training...\n",
      "Number of features:  4697\n",
      "\n",
      "Model correctly saved!\n",
      "\n",
      "──────────\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    model =  {\"name\": \"ComplementNB\", \"fun\": ComplementNB()}\n",
    "    \n",
    "    static_cd(model)\n",
    "    \n",
    "    incremental_cd(model)\n",
    "    \n",
    "    sliding_cd(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c802ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3f5e3eef",
    "b0733939",
    "10ddf5f3",
    "8990d29c",
    "5086c6c0",
    "ec8f41d9",
    "12bb38ce",
    "8351db08",
    "ce292406",
    "94862698",
    "BjVW0mYBEMMH",
    "07dae0b5",
    "89bcca8d",
    "da62310e",
    "C45M-Rribw5C",
    "8149c9fb",
    "019da1ef",
    "d0baccbd",
    "9e9b5b97",
    "f0dde321",
    "_nADI-wV9VAS",
    "qcT4gSRf8GDf",
    "22294383",
    "QiQ2PJVj8qRJ",
    "h3PdYjVs-k2u"
   ],
   "name": "BSblocker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
