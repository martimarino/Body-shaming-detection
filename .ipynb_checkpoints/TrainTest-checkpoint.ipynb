{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea26af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061c9ba",
   "metadata": {
    "id": "7061c9ba"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I8c7087a0E4I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18097,
     "status": "ok",
     "timestamp": 1657319393079,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "I8c7087a0E4I",
    "outputId": "2d75be9e-4726-46b9-ec50-fca052f7844d"
   },
   "outputs": [],
   "source": [
    "!pip install dataframe_image\n",
    "!pip install --upgrade pip\n",
    "!pip install selenium\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nZ3mdRyECEjG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 1301,
     "status": "error",
     "timestamp": 1657319399628,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "nZ3mdRyECEjG",
    "outputId": "7857d6bb-8d25-4c41-ba09-df76cd1c25d2"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# model selection and metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# import plot libs\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#from selenium import webdriver\n",
    "#driver = webdriver.Chrome(\"C:/Users/marti/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "\n",
    "rounds = 10\n",
    "folds = 10\n",
    "perc = \"85\"\n",
    "path = \"models_result/\"+perc+\"/\"\n",
    "\n",
    "\n",
    "def t_stat_interpret(t):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: yellow'` for queue values, white otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # degrees of freedom\n",
    "    p = 0.05\n",
    "    df = rounds - 1\n",
    "    t_table = pd.read_csv(\"./t_distribution_table.csv\")\n",
    "    c = float(t_table.loc[df, str(round(p / 2, 3))])\n",
    "\n",
    "    if t == \"\":\n",
    "        color = 'white'\n",
    "    else:\n",
    "        #color = 'white' if t > c or t < -c else 'yellow'\n",
    "        color = 'pink' if t > c or t < -c else 'lightgreen'\n",
    "    return 'background: % s' % color\n",
    "\n",
    "\n",
    "def scoring(pipeline, data, labels, iter):\n",
    "    results_10CV = []\n",
    "\n",
    "    # start iter\n",
    "    for i in range(1, iter + 1):\n",
    "        X, y = shuffle(data, labels, random_state=i * 42)\n",
    "        results_10CV.append(np.mean(cross_val_score(estimator=pipeline,\n",
    "                                                    X=X,\n",
    "                                                    y=y,\n",
    "                                                    cv=10,\n",
    "                                                    n_jobs=-1\n",
    "                                                    )))\n",
    "\n",
    "    return results_10CV\n",
    "\n",
    "\n",
    "# ------------------------ 10-fold cross validation ------------------------\n",
    "\n",
    "def cross_validation(models, tweets, targets):\n",
    "\n",
    "    # properties for new dataframe\n",
    "    idx = (model['name'] for model in models)\n",
    "    cols = ['Accuracy', 'Execution time', 'Std']\n",
    "    cvs = pd.DataFrame(np.zeros((11, 3)), columns=cols, index=idx)\n",
    "    # cm variable by the color palette from seaborn\n",
    "    cm = sns.light_palette(\"seagreen\", as_cmap=True)\n",
    "    cs = sns.light_palette(\"royalblue\", as_cmap=True)\n",
    "\n",
    "    for model in models:\n",
    "        start = time.time()\n",
    "\n",
    "        model['pipeline'] = Pipeline(steps=[('vect', CountVectorizer(ngram_range=(1, 1))),\n",
    "                                            ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n",
    "                                            ('fselect', SelectPercentile(chi2, percentile=int(perc))),\n",
    "                                            ('clf', model['fun'])])\n",
    "\n",
    "        model['values'] = scoring(model['pipeline'], tweets, targets, rounds)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        cvs.loc[model['name']] = [float((\"%.6f\" % np.mean(model['values'])).rstrip('0').rstrip('.')), \\\n",
    "                                  str(round((end - start),4))+\" s\", \\\n",
    "                                  float(\"%.6f\" % np.std(model['values']))]\n",
    "        cvs.sort_values('Accuracy', inplace=True, ascending=False)\n",
    "\n",
    "    print(\"\\nCross validation results:\\n\")\n",
    "    cvs.to_csv(path+\"training_result_\"+perc+\"/cross_val_result.csv\")\n",
    "    \n",
    "    cvs = cvs.style.background_gradient(cmap=cm, subset=['Accuracy'])\\\n",
    "                   .background_gradient(cmap=cs, subset=['Std'])\n",
    "    dfi.export(cvs, path+\"training_result_\"+perc+\"/cross_val_result.png\")\n",
    "    display(HTML(cvs.to_html()))\n",
    "\n",
    "    # discarded for execution time\n",
    "    discarded = [\"Bagging\", \"Random Forest\", \"Gradient Boosting\"]\n",
    "    # discarded for accuracy\n",
    "    discarded.extend([\"K Nearest\", \"Decision Tree\", \"Ada Boost\", \\\n",
    "                      \"Stochastic Gradient\"])\n",
    "    return discarded\n",
    "\n",
    "# ----------------- t-test evaluation from library -------------------------\n",
    "\n",
    "def t_test(models_selected):\n",
    "\n",
    "    all_t_stat = []\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for model in models_selected:\n",
    "        row = []\n",
    "        i += 1\n",
    "        j = 0\n",
    "        for another_model in models_selected:\n",
    "            j += 1\n",
    "            if (j < i + 1):\n",
    "                row.append(\"\")\n",
    "                continue\n",
    "            t_statistic, p_value = stats.ttest_rel(model['values'], \\\n",
    "                                                   another_model['values'])\n",
    "            # print(t_statistic, p_value)\n",
    "            row.append(t_statistic)\n",
    "\n",
    "        all_t_stat.append(row)\n",
    "\n",
    "    print(\"\\nT-test results:\\n\")\n",
    "\n",
    "    ttest_matrix = pd.DataFrame(all_t_stat, \n",
    "                                columns=(model['name'] for model in models_selected),\n",
    "                                index=(model['name'] for model in models_selected))\n",
    "    #delete empty column and row\n",
    "    del ttest_matrix['Logistic Regression']\n",
    "    ttest_matrix.drop(ttest_matrix.tail(1).index,inplace=True)\n",
    "    \n",
    "    ttest_matrix.to_csv(path+\"training_result_\"+perc+\"/t_test_result.csv\")\n",
    "    ttest_matrix = ttest_matrix.style.applymap(t_stat_interpret)\n",
    "    dfi.export(ttest_matrix, path+\"training_result_\"+perc+\"/t_test_result.png\")\n",
    "    display(HTML(ttest_matrix.to_html()))\n",
    "\n",
    "    discarded = []\n",
    "    discarded.append(\"MultinomialNB\")\n",
    "\n",
    "    return discarded\n",
    "\n",
    "\n",
    "# ---------------------- report and confusion matrix ----------------------- \n",
    "\n",
    "def get_report_conf_matrix(models, tweets, targets):\n",
    "\n",
    "    print(\"\\nReport and confusion matrix\")\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        print(model['name'])\n",
    "        predict = cross_val_predict(model['pipeline'], tweets, targets, cv=10)\n",
    "        rep = metrics.classification_report(targets, predict,\n",
    "                                            target_names=['0', '1'])\n",
    "        print(rep)\n",
    "      \n",
    "        # save report\n",
    "        rep = metrics.classification_report(targets, predict,\n",
    "                                    target_names=['0', '1'], output_dict=True)\n",
    "        df = pd.DataFrame(rep)\n",
    "        df.to_csv(path+'training_result_'+perc+'/'+model['name']+'-report.csv')\n",
    "        \n",
    "        # calculate and print confusion matrix\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            targets,\n",
    "            predict,\n",
    "            values_format='g',\n",
    "            display_labels=[0,1],\n",
    "            cmap=plt.cm.Blues\n",
    "        )\n",
    "        disp.ax_.set_title(\"Confusion matrix\")\n",
    "\n",
    "        print(disp.confusion_matrix)\n",
    "        disp.figure_.savefig(path+'training_result_'+perc+'/'+model['name']+'-confusion_matrix.png')\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def train_models(data):\n",
    "\n",
    "    data.sample(frac=1)\n",
    "\n",
    "    tweets = data.text\n",
    "    targets = data.target\n",
    "\n",
    "\n",
    "    # models = name | fun | pipeline | values |\n",
    "    models = [\n",
    "        {\"name\": \"Logistic Regression\", \"fun\": LogisticRegression()},\n",
    "        {\"name\": \"SVM\", \"fun\": svm.SVC()},\n",
    "        {\"name\": \"Decision Tree\", \"fun\": DecisionTreeClassifier()},\n",
    "        {\"name\": \"MultinomialNB\", \"fun\": MultinomialNB()},\n",
    "        {\"name\": \"Gradient Boosting\", \"fun\": GradientBoostingClassifier()},\n",
    "        {\"name\": \"ComplementNB\", \"fun\": ComplementNB()},\n",
    "        {\"name\": \"K Nearest\", \"fun\": KNeighborsClassifier()},\n",
    "        {\"name\": \"Random Forest\", \"fun\": RandomForestClassifier()},\n",
    "        {\"name\": \"Ada Boost\", \"fun\": AdaBoostClassifier()},\n",
    "        {\"name\": \"Bagging\", \"fun\": BaggingClassifier()},\n",
    "        {\"name\": \"Stochastic Gradient\", \"fun\": SGDClassifier()}\n",
    "    ]\n",
    "\n",
    "    # analyze classifiers\n",
    "\n",
    "    discarded = cross_validation(models, tweets, targets)\n",
    "\n",
    "    models_selected = [s for s in models if s['name'] not in discarded]\n",
    "\n",
    "    discarded = t_test(models_selected)\n",
    "\n",
    "    models_selected = [s for s in models_selected if s['name'] not in discarded]\n",
    "\n",
    "    get_report_conf_matrix(models, tweets, targets)\n",
    "\n",
    "\n",
    "    # models building\n",
    "\n",
    "    for model in models_selected:\n",
    "      \n",
    "        m = model['pipeline'].fit(tweets, targets)\n",
    "        \n",
    "        # save models\n",
    "        filename = model['name'] + '.sav'\n",
    "        pickle.dump(m, open(path+'models_'+perc+'/'+filename, 'wb'))\n",
    "\n",
    "    print(\"\\nModels correctly saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57296676",
   "metadata": {
    "id": "57296676"
   },
   "source": [
    "# Training flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gfE-4WutQbSY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1657314651911,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "gfE-4WutQbSY",
    "outputId": "34468158-c515-4c02-ec8f-0945cda94093"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluKY0xyipeX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 255946,
     "status": "error",
     "timestamp": 1657318605447,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "fluKY0xyipeX",
    "outputId": "640b7bea-c04d-45b0-b929-9e22c3f50b36",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from IPython.display import HTML\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    training_set_file = 'labeled/12-01-rebalanced-only-labeled.csv'\n",
    "    train_data = pd.read_csv(training_set_file, index_col=False, delimiter=\",\")\n",
    "\n",
    "    train_data = preprocess(train_data)\n",
    "    train_data = elaborate(train_data)\n",
    "\n",
    "    # print(train_data.shape)\n",
    "    #tot0 = len(train_data[train_data.target == '0'])\n",
    "    #tot1 = len(train_data[train_data.target == '1'])\n",
    "\n",
    "    train_models(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XsIMhLG8hhB6",
   "metadata": {
    "id": "XsIMhLG8hhB6"
   },
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qqFqE1YUZ-zk",
   "metadata": {
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1657294606236,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "qqFqE1YUZ-zk"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# model selection and metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# import plot libs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def test_models(data):\n",
    "\n",
    "    tweets = data['text']\n",
    "    targets = data['target']\n",
    "\n",
    "    models = [\n",
    "        {\"name\": \"Logistic Regression\", \"fun\": LogisticRegression()},\n",
    "        {\"name\": \"SVM\", \"fun\": svm.SVC()},\n",
    "        {\"name\": \"ComplementNB\", \"fun\": ComplementNB()}\n",
    "    ]\n",
    "\n",
    "    # load the model from disk\n",
    "    for model in models:\n",
    "\n",
    "        loaded_model = pickle.load(open(path+'models_'+perc+'/'+model['name']+'.sav', 'rb'))\n",
    "        print(model['name'])\n",
    "        score = loaded_model.score(tweets, targets)\n",
    "        print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "        y_predict = loaded_model.predict(tweets)\n",
    "\n",
    "        rep = classification_report(targets, y_predict,\n",
    "                                              target_names=['0', '1'])\n",
    "        print(rep, '\\n')\n",
    "\n",
    "        # save reports\n",
    "        rep = classification_report(targets, y_predict,\n",
    "                                    target_names=['0', '1'], output_dict=True)\n",
    "        df = pd.DataFrame(rep).transpose()\n",
    "        df.to_csv(path+'test_result_'+perc+'/'+model['name']+'-report.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hfvNWuQQ-xfk",
   "metadata": {
    "id": "hfvNWuQQ-xfk"
   },
   "source": [
    "# Test flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F2Y6-W7B-2SH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1657293702570,
     "user": {
      "displayName": "MARTINA MARINO",
      "userId": "06117242016215180196"
     },
     "user_tz": -120
    },
    "id": "F2Y6-W7B-2SH",
    "outputId": "dc95ec0e-5e32-44df-8c7f-d83dc4cb4782"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from IPython.display import HTML\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    test_set_file = './labeled/2022-02-labeled-only.csv'\n",
    "    test_data = pd.read_csv(test_set_file, index_col=False, delimiter=\",\")\n",
    "    \n",
    "    test_data = preprocess(test_data)\n",
    "    test_data = elaborate(test_data)\n",
    "\n",
    "    # print(test_data.shape)\n",
    "    #tot0 = len(train_data[test_data.target == '0'])\n",
    "    #tot1 = len(train_data[test_data.target == '1'])\n",
    "\n",
    "    test_models(test_data)\n",
    "    #we consider just yellow -> null hp non rejected -> similar to each other -> best Complement e Logistic? Migliori accuracy e execution time"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3f5e3eef",
    "b0733939",
    "10ddf5f3",
    "8990d29c",
    "5086c6c0",
    "ec8f41d9",
    "12bb38ce",
    "8351db08",
    "ce292406",
    "94862698",
    "BjVW0mYBEMMH",
    "07dae0b5",
    "89bcca8d",
    "da62310e",
    "C45M-Rribw5C",
    "8149c9fb",
    "019da1ef",
    "d0baccbd",
    "9e9b5b97",
    "f0dde321",
    "_nADI-wV9VAS",
    "qcT4gSRf8GDf",
    "22294383",
    "QiQ2PJVj8qRJ",
    "h3PdYjVs-k2u"
   ],
   "name": "BSblocker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
